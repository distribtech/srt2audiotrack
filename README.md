# srt2audiotrack

`srt2audiotrack` creates polished, multilingual voice-over tracks from subtitle files while keeping the original mix intact. It combines text normalisation, high-quality TTS synthesis, intelligent mixing, and FFmpeg-based mastering into a resumable pipeline that can be orchestrated across multiple workers.

## Key capabilities
- ğŸš€ **End-to-end pipeline** â€“ automatically rewrites subtitles, generates aligned speech, balances against the original soundtrack, and delivers a muxed video output. ã€F:srt2audiotrack/pipeline.pyâ€ L185-L333ã€‘
- ğŸ—£ï¸ **Speaker-aware synthesis** â€“ supports multiple reference voices with per-speaker speed curves derived from `speeds.csv` metadata. Missing curves are generated on-demand. ã€F:srt2audiotrack/subtitle_csv.pyâ€ L137-L213ã€‘
- ğŸ§° **Resumable by design** â€“ every processing stage caches its artefacts so that interrupted runs simply pick up where they left off. ã€F:srt2audiotrack/pipeline.pyâ€ L246-L333ã€‘
- ğŸ“¦ **Job manifests & locking** â€“ optional manifest files let you queue work for farms of machines while cooperative lock files prevent duplicate processing. ã€F:srt2audiotrack/cli.pyâ€ L77-L176ã€‘ã€F:srt2audiotrack/pipeline.pyâ€ L33-L361ã€‘

## Installation
1. Create and activate an environment (example using conda):
   ```bash
   conda create -n srt2audio python=3.10
   conda activate srt2audio
   ```
2. Install the core runtime dependencies:
   ```bash
   pip install f5-tts demucs librosa soundfile numpy ffmpeg-python
   ```
3. Install the project requirements:
   ```bash
   pip install -r requirements.txt
   ```
4. Ensure `ffmpeg` is available on your `PATH` for muxing and loudness normalisation.

## Preparing the `VOICE` library
The CLI expects a `VOICE` subfolder alongside each subtitle/video set. Populate it with:
- Reference `.wav` files for each speaker. ã€F:srt2audiotrack/subtitle_csv.pyâ€ L162-L194ã€‘
- Matching `.txt` transcripts so the tool can validate training text. ã€F:srt2audiotrack/subtitle_csv.pyâ€ L196-L203ã€‘
- Optional `speeds.csv` curves stored under a folder named after the speaker (generated automatically if missing). ã€F:srt2audiotrack/subtitle_csv.pyâ€ L177-L213ã€‘
- A shared `vocabular.txt` file for search/replace rules; it will be created if absent. ã€F:srt2audiotrack/vocabulary.pyâ€ L5-L13ã€‘

See `tests/one_voice` for an example directory layout.

## Usage
### Quick start
Process every `.srt` file in a directory, producing muxed videos beside the originals:
```bash
python -m srt2audiotrack --subtitle path/to/records
```
Process a single subtitle/video pair:
```bash
python -m srt2audiotrack --subtitle path/to/video.srt
```

### Working with manifests and multiple workers
- Use `--job-manifest-dir` to point to a directory containing plain-text job lists (one subtitle path per line, comments allowed). Duplicate paths are deduplicated automatically. ã€F:srt2audiotrack/cli.pyâ€ L26-L41ã€‘ã€F:srt2audiotrack/cli.pyâ€ L77-L140ã€‘
- Provide `--worker-id` (or rely on the hostname) so lock files record who owns a job. Locks refresh on a heartbeat and are reclaimed when stale, enabling safe restarts across machines. ã€F:srt2audiotrack/cli.pyâ€ L85-L122ã€‘ã€F:srt2audiotrack/pipeline.pyâ€ L210-L361ã€‘

### Output structure and resume behaviour
For a subtitle named `example.srt`, intermediate files live under `OUTPUT/example/` while the final muxed video is written beside the subtitle (or into `--output_folder`). ã€F:srt2audiotrack/pipeline.pyâ€ L171-L333ã€‘ The pipeline skips any step whose artefact already exists, so reruns only process missing stages.

### Command line options
| Option | Description | Default |
|--------|-------------|---------|
| `--subtitle` | Path to subtitle file or directory to scan | `records` |
| `--speeds` | Path to default speeds table | `speeds.csv` |
| `--delay` | Minimum gap used when collapsing subtitle lines | `0.00001` |
| `--voice` | Reference voice file used for diagnostics | `basic_ref_en.wav` |
| `--text` | Reference text used with `--voice` | `some call me nature, others call me mother nature.` |
| `--videoext` | Expected video extension when scanning folders | `.mp4` |
| `--srtext` | Subtitle extension when scanning folders | `.srt` |
| `--outfileending` | Suffix for rendered video names | `_out_mix.mp4` |
| `--vocabular` | Override path to vocabulary file | `vocabular.txt` |
| `--config` / `-c` | Optional TOML configuration file | `basic.toml` |
| `--acomponiment_coef` | Mix level for the background accompaniment | `0.2` |
| `--voice_coef` | Mix level for generated voice | `0.2` |
| `--output_folder` | Custom directory for pipeline artefacts and final video | same as subtitle parent |
| `--job-manifest-dir` | Folder containing job manifest files | *(empty)* |
| `--worker-id` | Identifier recorded in lock files | hostname or `PIPELINE_WORKER_ID` |
| `--lock-timeout` | Seconds before a lock is considered stale | `1800.0` |
| `--lock-heartbeat` | Seconds between lock refreshes | `60.0` |

(See `python -m srt2audiotrack --help` for the authoritative list.) ã€F:srt2audiotrack/cli.pyâ€ L44-L123ã€‘

## What the pipeline does
1. **Subtitle normalisation** â€“ applies vocabulary replacements and prepares `_0_mod.srt`. ã€F:srt2audiotrack/pipeline.pyâ€ L246-L254ã€‘
2. **CSV enrichment** â€“ adds speaker assignments and speed hints before triggering TTS generation. ã€F:srt2audiotrack/pipeline.pyâ€ L254-L276ã€‘
3. **Timing corrections & stitching** â€“ fixes end times and builds a full FLAC narration track. ã€F:srt2audiotrack/pipeline.pyâ€ L278-L293ã€‘
4. **Source audio prep** â€“ extracts and separates the original soundtrack, resampling and normalising the accompaniment. ã€F:srt2audiotrack/pipeline.pyâ€ L295-L309ã€‘ã€F:srt2audiotrack/audio_utils.pyâ€ L24-L99ã€‘
5. **Dynamic mixing** â€“ applies interval-based volume shaping before muxing with FFmpeg. ã€F:srt2audiotrack/pipeline.pyâ€ L311-L333ã€‘ã€F:srt2audiotrack/ffmpeg_utils.pyâ€ L1-L52ã€‘

## Scheme of work

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Subtitle           â”‚   â”‚ CSV & speaker      â”‚   â”‚ Timing correction &     â”‚
â”‚ normalisation      â”‚â”€â”€â–¶â”‚ enrichment         â”‚â”€â”€â–¶â”‚ narration stitching     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                       â”‚                          â”‚
              â–¼                       â–¼                          â–¼
       Vocabulary rules        Speaker metadata           FLAC narration
              â”‚                       â”‚                          â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼                         â–¼
                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                   â”‚ Source audio prep  â”‚   â”‚ Dynamic mixing &   â”‚
                   â”‚ (demucs, loudness) â”‚â”€â”€â–¶â”‚ final muxing       â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Multi-application orchestration

The pipeline coordinates several cooperating processes and external tools. The following
ASCII sketch shows how manifests, workers, and helper applications interact when processing
jobs in parallel:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Manifest directory       â”‚  fan   â”‚   Worker processes       â”‚
â”‚ (*.txt job lists)        â”‚â”€â”€outâ”€â”€â–¶â”‚ (CLI invocations, one    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚  per machine/container)   â”‚
        â–²                           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                   â”‚
        â”‚ reload manifests                  â”‚ acquire lock per job
        â”‚                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Lock files (*.lock)      â”‚â—€â”€â”€â”€â”€â”€â”€â–¶â”‚ Pipeline coordinator     â”‚
â”‚ (ownership + heartbeat)  â”‚        â”‚ (Python pipeline stages) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â”‚ dispatches work units
                                            â–¼
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚ Vocabulary  â”‚ TTS engine  â”‚ Demucs/FFmpegâ”‚ Mixdown/FFmpegâ”‚
       â”‚ management  â”‚ (f5-tts)    â”‚ separation   â”‚ mux & export  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Each worker watches the manifest directory and claims available jobs by touching or updating
the corresponding `.lock` file. The lock stores the worker ID and heartbeat timestamps so
that other workers can safely skip in-progress work or reclaim stale jobs. The pipeline
continues through the normalisation, synthesis, separation, and muxing stages, delegating
to specialised apps such as `demucs` and `ffmpeg` where needed.

### Working with `.lock` files

- **Inspection** â€“ Lock files live beside the subtitle output directory (e.g.
  `OUTPUT/example/example.lock`). They are plain text and can be opened to check the
  current owner, timestamps, and heartbeat interval.
- **Refreshing** â€“ Active workers refresh their lock on a background heartbeat. If a
  worker is terminated unexpectedly, the lock becomes stale after `--lock-timeout`
  seconds and other workers will automatically reclaim the job.
- **Manual recovery** â€“ When coordinating manually, you can delete a stale lock file if
  you are certain no other worker is operating on the job. Upon the next manifest scan,
  an available worker will obtain a fresh lock and resume from cached artefacts.

## Python API
Use the high-level helper to invoke the pipeline programmatically:
```python
from pathlib import Path
from srt2audiotrack import SubtitlePipeline

SubtitlePipeline.create_video_with_english_audio(
    video_path="video.mp4",
    subtitle=Path("subtitles.srt"),
    speakers=speakers_config,
    default_speaker=speakers_config["en"],
    vocabular=Path("VOICE/vocabular.txt"),
    acomponiment_coef=0.3,
    voice_coef=0.2,
    output_folder=Path("out"),
)
```
This wrapper wires up the same pipeline used by the CLI while allowing advanced dependency injection for testing. ã€F:srt2audiotrack/pipeline.pyâ€ L372-L403ã€‘

## Troubleshooting
- Verify the external CLIs are available:
  ```bash
  python -m whisper --help
  python -m demucs.separate --help
  python -m f5_tts.cli --help
  ```
- If a job is skipped with a lock warning, inspect the `.lock` file inside the subtitle output folder to confirm the active worker ID or delete stale locks after the timeout has elapsed. ã€F:srt2audiotrack/pipeline.pyâ€ L33-L361ã€‘

Happy dubbing!
